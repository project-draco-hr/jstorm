{
  StormClusterState clusterState=data.getStormClusterState();
  try {
    List<String> active_topologys=clusterState.assignments(null);
    if (active_topologys == null) {
      LOG.info("Failed to get active topologies");
      return;
    }
    for (    String topologyid : active_topologys) {
      if (clusterState.storm_base(topologyid,null) == null) {
        continue;
      }
      LOG.debug("Check tasks " + topologyid);
      Set<Integer> taskIds=clusterState.task_ids(topologyid);
      if (taskIds == null) {
        LOG.info("Failed to get task ids of " + topologyid);
        continue;
      }
      Assignment assignment=clusterState.assignment_info(topologyid,null);
      Set<Integer> deadTasks=new HashSet<Integer>();
      boolean needReassign=false;
      for (      Integer task : taskIds) {
        boolean isTaskDead=NimbusUtils.isTaskDead(data,topologyid,task);
        if (isTaskDead == true) {
          deadTasks.add(task);
          needReassign=true;
        }
      }
      TopologyTaskHbInfo topologyHbInfo=data.getTasksHeartbeat().get(topologyid);
      if (needReassign == true) {
        if (topologyHbInfo != null) {
          int topologyMasterId=topologyHbInfo.get_topologyMasterId();
          if (deadTasks.contains(topologyMasterId)) {
            deadTasks.clear();
            if (assignment != null) {
              ResourceWorkerSlot resource=assignment.getWorkerByTaskId(topologyMasterId);
              if (resource != null)               deadTasks.addAll(resource.getTasks());
 else               deadTasks.add(topologyMasterId);
            }
          }
 else {
            Map<Integer,TaskHeartbeat> taskHbs=topologyHbInfo.get_taskHbs();
            int launchTime=JStormUtils.parseInt(data.getConf().get(Config.NIMBUS_TASK_LAUNCH_SECS));
            if (taskHbs == null || taskHbs.get(topologyMasterId) == null || taskHbs.get(topologyMasterId).get_uptime() < launchTime) {
              return;
            }
          }
          Map<Integer,ResourceWorkerSlot> deadTaskWorkers=new HashMap<>();
          for (          Integer task : deadTasks) {
            LOG.info("Found " + topologyid + ",taskid:"+ task+ " is dead");
            ResourceWorkerSlot resource=null;
            if (assignment != null)             resource=assignment.getWorkerByTaskId(task);
            if (resource != null) {
              deadTaskWorkers.put(task,resource);
              Date now=new Date();
              String nowStr=TimeFormat.getSecond(now);
              String errorInfo="Task-" + task + " is dead on "+ resource.getHostname()+ ":"+ resource.getPort()+ ", "+ nowStr;
              LOG.info(errorInfo);
              clusterState.report_task_error(topologyid,task,errorInfo,null);
            }
          }
          if (deadTaskWorkers.size() > 0) {
            TaskDeadEvent event=new TaskDeadEvent();
            event.clusterName=data.getClusterName();
            event.topologyId=topologyid;
            event.deadTasks=deadTaskWorkers;
            event.timestamp=System.currentTimeMillis();
            data.getMetricRunnable().pushEvent(event);
          }
        }
        NimbusUtils.transition(data,topologyid,false,StatusType.monitor);
      }
      if (topologyHbInfo != null) {
        try {
          clusterState.topology_heartbeat(topologyid,topologyHbInfo);
        }
 catch (        Exception e) {
          LOG.error("Failed to update task heartbeat info to ZK for " + topologyid,e);
        }
      }
    }
  }
 catch (  Exception e) {
    LOG.error(e.getMessage(),e);
  }
}
