{
  super(task,_transfer_fn,storm_conf,innerTaskTransfer,sysTopologyCxt,userTopologyCxt,_task_stats,taskStatus,_report_error);
  this.bolt=_bolt;
  this.tuple_start_times=new RotatingMap<Tuple,Long>(Acker.TIMEOUT_BUCKET_NUM);
  this.ackerNum=JStormUtils.parseInt(storm_conf.get(Config.TOPOLOGY_ACKER_EXECUTORS));
  IOutputCollector output_collector=new BoltCollector(message_timeout_secs,_report_error,_send_fn,storm_conf,_transfer_fn,sysTopologyCxt,taskId,tuple_start_times,_task_stats);
  outputCollector=new OutputCollector(output_collector);
  boltExeTimer=JStormMetrics.registerTaskHistogram(taskId,MetricDef.EXECUTE_TIME);
  Object tickFrequence=storm_conf.get(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS);
  if (tickFrequence != null) {
    Integer frequence=JStormUtils.parseInt(tickFrequence);
    TickTupleTrigger tickTupleTrigger=new TickTupleTrigger(sysTopologyCxt,frequence,idStr + Constants.SYSTEM_TICK_STREAM_ID,exeQueue);
    tickTupleTrigger.register();
  }
  if (ConfigExtension.isTaskBatchTuple(storm_conf)) {
    TaskBatchFlushTrigger batchFlushTrigger=new TaskBatchFlushTrigger(5,idStr + Constants.SYSTEM_COMPONENT_ID,(TaskBatchTransfer)_transfer_fn);
    batchFlushTrigger.register(TimeUnit.MILLISECONDS);
  }
  try {
    WorkerClassLoader.switchThreadContext();
    bolt.prepare(storm_conf,userTopologyCtx,outputCollector);
  }
 catch (  Throwable e) {
    error=e;
    LOG.error("bolt prepare error ",e);
    report_error.report(e);
  }
 finally {
    WorkerClassLoader.restoreThreadContext();
  }
  LOG.info("Successfully create BoltExecutors " + idStr);
}
